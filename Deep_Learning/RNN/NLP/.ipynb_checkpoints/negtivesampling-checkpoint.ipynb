{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "import hashlib\n",
    "import collections\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has already been preprocessed. Each line of the dataset acts as a sentence. All the words in a sentence are separated by spaces. In the word embedding task, each word is a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences: 42069'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_ptb():\n",
    "    with open(os.path.join(sys.path[0], \"ptb.train.txt\"), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "\n",
    "sentences = read_ptb() # list of list of words\n",
    "f'# sentences: {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating vocabulary\n",
    "\n",
    "def tokenize(lines, token='word'):\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('ERROR: unknown token type: ' + token)\n",
    "        \n",
    "class Vocab:  #@save\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # Sort according to frequencies\n",
    "        counter = count_corpus(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The index for the unknown token is 0\n",
    "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
    "        uniq_tokens += [token for token, freq in self.token_freqs\n",
    "                        if freq >= min_freq and token not in uniq_tokens]\n",
    "        self.idx_to_token, self.token_to_idx = [], dict()\n",
    "        for token in uniq_tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"Count token frequencies.\"\"\"\n",
    "    # Here `tokens` is a 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flatten a list of token lists into a list of tokens\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsampling ('a','the',....)\n",
    "\n",
    "# Specifically, each indexed word  wi  in the dataset will drop out at a certain probability.\n",
    "# The dropout probability is given as: max(1-t/f(w_i),0)\n",
    "# f(w_i) is ratio of instances word w_i to total number of words\n",
    "# t is Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(sentences, vocab):\n",
    "    # Map low frequency words into <unk>\n",
    "    sentences = [[vocab.idx_to_token[vocab[tk]] for tk in line]\n",
    "                 for line in sentences]\n",
    "#     print(sentences[1])\n",
    "    # Count the frequency for each word\n",
    "    counter = count_corpus(sentences)\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # Return True if to keep this token during subsampling\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    # Now do the subsampling\n",
    "    return [[tk for tk in line if keep(tk)] for line in sentences]\n",
    "\n",
    "subsampled = subsampling(sentences, vocab)\n",
    "# subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set_figsize()\n",
    "plt.hist([[len(line) for line in sentences],\n",
    "              [len(line) for line in subsampled]])\n",
    "plt.xlabel('# tokens per sentence')\n",
    "plt.ylabel('count')\n",
    "plt.legend(['origin', 'subsampled']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"the\": before=50770, after=2102'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'# of \"{token}\": '\n",
    "            f'before={sum([line.count(token) for line in sentences])}, '\n",
    "            f'after={sum([line.count(token) for line in subsampled])}')\n",
    "\n",
    "compare_counts('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"join\": before=45, after=45'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[392, 2467, 656, 2157, 948, 520, 436, 3660]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct corpus\n",
    "\n",
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # Each sentence needs at least 2 words to form a \"central target word\n",
    "        # - context word\" pair\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "#         print(line,\"hi\")\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # Context window centered at i\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # Exclude the central target word from the context words\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center 0 has contexts [1, 2]\n",
      "center 1 has contexts [0, 2]\n",
      "center 2 has contexts [1, 3]\n",
      "center 3 has contexts [2, 4]\n",
      "center 4 has contexts [2, 3, 5, 6]\n",
      "center 5 has contexts [4, 6]\n",
      "center 6 has contexts [5]\n",
      "center 7 has contexts [8, 9]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('center', center, 'has contexts', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# center-context pairs: 352935'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# center-context pairs: {len(all_centers)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 2, 0, 2, 0, 1, 2, 2, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Negative sampling\n",
    "\n",
    "class RandomGenerator:\n",
    "    \"\"\"Draw a random int in [0, n] according to n sampling weights.\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        self.population = list(range(len(sampling_weights)))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i-1]\n",
    "\n",
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts, corpus, K):\n",
    "    counter = count_corpus(corpus)\n",
    "    sampling_weights = [counter[i]**0.75 for i in range(len(counter))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "#         print(context)\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise words cannot be context words\n",
    "#             print(neg)\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "#         print(len(contexts),len(negatives))      \n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, corpus, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape(\n",
    "        (-1, 1)), torch.tensor(contexts_negatives), torch.tensor(masks),\n",
    "            torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "class PTBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index], self.negatives[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.centers)\n",
    "    \n",
    "dataset = PTBDataset(\n",
    "    all_centers, all_contexts, all_negatives)\n",
    "\n",
    "data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                  collate_fn=batchify,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: torch.Size([512, 1])\n",
      "contexts_negatives shape: torch.Size([512, 60])\n",
      "masks shape: torch.Size([512, 60])\n",
      "labels shape: torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter embedding_weight (torch.Size([20, 4]), dtype={embed.weight.dtype})\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
    "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
    "      'dtype={embed.weight.dtype})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
    "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBCELoss(nn.Module):\n",
    "    \"BCEWithLogitLoss with masking on call.\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "loss = SigmoidBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "net = nn.Sequential(nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size),\n",
    "                    nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Embedding:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    metric = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        num_batches =  len(data_iter)\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            center, context_negative, mask, label = [\n",
    "                data.to(device) for data in batch]\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (loss(pred.reshape(label.shape).float(), label.float(), mask)\n",
    "                     / mask.sum(axis=1) * mask.shape[1])\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            metric.append(l.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 6\n",
    "train(net, data_iter, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.588: shape\n",
      "cosine sim=0.581: memory\n",
      "cosine sim=0.569: image\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[vocab[query_token]]\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # Remove the input words\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.idx_to_token[i]}')\n",
    "\n",
    "get_similar_tokens('chips', 3, net[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
