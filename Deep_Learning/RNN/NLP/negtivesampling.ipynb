{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "import hashlib\n",
    "import collections\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has already been preprocessed. Each line of the dataset acts as a sentence. All the words in a sentence are separated by spaces. In the word embedding task, each word is a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences: 42069'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_ptb():\n",
    "    with open(os.path.join(sys.path[0], \"ptb.train.txt\"), \"r\") as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "\n",
    "sentences = read_ptb() # list of list of words\n",
    "f'# sentences: {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating vocabulary\n",
    "\n",
    "def tokenize(lines, token='word'):\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('ERROR: unknown token type: ' + token)\n",
    "        \n",
    "class Vocab:  #@save\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # Sort according to frequencies\n",
    "        counter = count_corpus(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The index for the unknown token is 0\n",
    "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
    "        uniq_tokens += [token for token, freq in self.token_freqs\n",
    "                        if freq >= min_freq and token not in uniq_tokens]\n",
    "        self.idx_to_token, self.token_to_idx = [], dict()\n",
    "        for token in uniq_tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"Count token frequencies.\"\"\"\n",
    "    # Here `tokens` is a 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flatten a list of token lists into a list of tokens\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsampling ('a','the',....)\n",
    "\n",
    "# Specifically, each indexed word  wi  in the dataset will drop out at a certain probability.\n",
    "# The dropout probability is given as: max(1-t/f(w_i),0)\n",
    "# f(w_i) is ratio of instances word w_i to total number of words\n",
    "# t is Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(sentences, vocab):\n",
    "    # Map low frequency words into <unk>\n",
    "    sentences = [[vocab.idx_to_token[vocab[tk]] for tk in line]\n",
    "                 for line in sentences]\n",
    "#     print(sentences[1])\n",
    "    # Count the frequency for each word\n",
    "    counter = count_corpus(sentences)\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # Return True if to keep this token during subsampling\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    # Now do the subsampling\n",
    "    return [[tk for tk in line if keep(tk)] for line in sentences]\n",
    "\n",
    "subsampled = subsampling(sentences, vocab)\n",
    "# subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set_figsize()\n",
    "plt.hist([[len(line) for line in sentences],\n",
    "              [len(line) for line in subsampled]])\n",
    "plt.xlabel('# tokens per sentence')\n",
    "plt.ylabel('count')\n",
    "plt.legend(['origin', 'subsampled']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"the\": before=50770, after=2023'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'# of \"{token}\": '\n",
    "            f'before={sum([line.count(token) for line in sentences])}, '\n",
    "            f'after={sum([line.count(token) for line in subsampled])}')\n",
    "\n",
    "compare_counts('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"join\": before=45, after=45'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[392, 2115, 406]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct corpus\n",
    "\n",
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # Each sentence needs at least 2 words to form a \"central target word\n",
    "        # - context word\" pair\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "#         print(line,\"hi\")\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # Context window centered at i\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # Exclude the central target word from the context words\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center 0 has contexts [1, 2]\n",
      "center 1 has contexts [0, 2]\n",
      "center 2 has contexts [0, 1, 3, 4]\n",
      "center 3 has contexts [2, 4]\n",
      "center 4 has contexts [3, 5]\n",
      "center 5 has contexts [4, 6]\n",
      "center 6 has contexts [5]\n",
      "center 7 has contexts [8, 9]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('center', center, 'has contexts', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# center-context pairs: 352566'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# center-context pairs: {len(all_centers)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 2, 2, 2, 1, 1, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Negative sampling\n",
    "\n",
    "class RandomGenerator:\n",
    "    \"\"\"Draw a random int in [0, n] according to n sampling weights.\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        self.population = list(range(len(sampling_weights)))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i-1]\n",
    "\n",
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts, corpus, K):\n",
    "    counter = count_corpus(corpus)\n",
    "    sampling_weights = [counter[i]**0.75 for i in range(len(counter))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "#         print(context)\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise words cannot be context words\n",
    "#             print(neg)\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "#         print(len(contexts),len(negatives))      \n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, corpus, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape(\n",
    "        (-1, 1)), torch.tensor(contexts_negatives), torch.tensor(masks),\n",
    "            torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "class PTBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index], self.negatives[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.centers)\n",
    "    \n",
    "dataset = PTBDataset(\n",
    "    all_centers, all_contexts, all_negatives)\n",
    "\n",
    "data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                  collate_fn=batchify,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: torch.Size([512, 1])\n",
      "contexts_negatives shape: torch.Size([512, 60])\n",
      "masks shape: torch.Size([512, 60])\n",
      "labels shape: torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter embedding_weight (torch.Size([20, 4]), dtype={embed.weight.dtype})\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
    "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
    "      'dtype={embed.weight.dtype})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
    "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBCELoss(nn.Module):\n",
    "    \"BCEWithLogitLoss with masking on call.\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "loss = SigmoidBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "net = nn.Sequential(nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size),\n",
    "                    nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Embedding:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    metric = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        num_batches =  len(data_iter)\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            center, context_negative, mask, label = [\n",
    "                data.to(device) for data in batch]\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (loss(pred.reshape(label.shape).float(), label.float(), mask)\n",
    "                     / mask.sum(axis=1) * mask.shape[1])\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            metric.append(l.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 6\n",
    "train(net, data_iter, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.660: memory\n",
      "cosine sim=0.648: faster\n",
      "cosine sim=0.554: disks\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[vocab[query_token]]\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # Remove the input words\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.idx_to_token[i]}')\n",
    "\n",
    "get_similar_tokens('chips', 3, net[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
